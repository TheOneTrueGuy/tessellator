{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3NMYLkPxp8koajtZ2C7iX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheOneTrueGuy/tessellator/blob/main/Tesselator_with_Groq_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-NBq8pvAnPM"
      },
      "outputs": [],
      "source": [
        "!pip install groq\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# performing a chat completion\n",
        "from groq import Groq\n",
        "from google.colab import userdata\n",
        "# this assumes you have set your Groq API key as a Secret under the key icon\n",
        "GROQ_API_KEY= userdata.get('GROQ_API_KEY')\n",
        "client = Groq(\n",
        "    api_key=GROQ_API_KEY #os.environ.get(\"GROQ_API_KEY\"),\n",
        ")\n",
        "\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Explain the importance of low latency LLMs\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        ")\n",
        "#just a test for now\n",
        "print(chat_completion.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "szwm4lvhAwQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from collections import deque\n",
        "import networkx as nx\n",
        "from groq import Groq\n",
        "inport os\n",
        "\n",
        "concepts = set()  # Set to store unique concepts encountered\n",
        "\n",
        "# Function to query the LLM for related concepts (using OpenAI API)\n",
        "#openai.api_key = \"none\"\n",
        "#openai.api_base = \"http://localhost:1234/v1\"\n",
        "#client = openai(base_url=\"http://localhost:1234/v1\", api_key=\"not-needed\")\n",
        "def prompt_lm(prompt):\n",
        "    print(\"inside\")\n",
        "    completion =     response = openai.ChatCompletion.create(model=\"local_model\",\n",
        "      messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Employ concepts as poles on an axis to find their perpendicular partners in a tessellating graph function for exploring concept spaces.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ],\n",
        "      temperature=0.17,\n",
        "      )\n",
        "    print(completion)\n",
        "\n",
        "    return [choice.text.strip() for choice in completion.choices]\n",
        "\n",
        "def Groq_call(prompt):\n",
        "  chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"Employ concepts as points along a line to find their perpendicular partners in a tessellating graph function for exploring concept spaces.\"},\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt,\n",
        "        }\n",
        "    ],\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "  )\n",
        "  print(chat_completion.choices[0].message.content)\n",
        "  return chat_completion.choices[0].message.content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Recursive function to build the concept graph\n",
        "def build_concept_graph(concept1, concept2, depth=0, max_depth=3):\n",
        "    # Initialize an empty graph using NetworkX\n",
        "    graph = nx.Graph()\n",
        "\n",
        "    # Add seed concepts as nodes to the graph\n",
        "    graph.add_node(concept1)\n",
        "    graph.add_node(concept2)\n",
        "\n",
        "    # Base case: if maximum depth is reached, return the graph\n",
        "    if depth >= max_depth:\n",
        "        return graph\n",
        "\n",
        "    # Query LLM for related concepts perpendicular to the current axis\n",
        "    related_concepts_list = prompt_lm(f\"Considering concepts '{concept1}' and '{concept2}' as 2 points on a line between their meanings, what concepts are most perpendicular to this axis? reply concisely as possible with a short concept subject heading or title.\")\n",
        "\n",
        "    # Add retrieved concepts as nodes to the graph\n",
        "    for related_concept in related_concepts_list:\n",
        "        if related_concept not in graph.nodes:\n",
        "            graph.add_node(related_concept)\n",
        "\n",
        "        # Add edges between current concepts and retrieved concepts\n",
        "        graph.add_edge(concept1, related_concept)\n",
        "        graph.add_edge(concept2, related_concept)\n",
        "\n",
        "        # Recursively call the function with the new perpendicular concept\n",
        "        child_graph = build_concept_graph(concept1, related_concept, depth=depth+1, max_depth=max_depth)\n",
        "        child_graph = build_concept_graph(concept2, related_concept, depth=depth+1, max_depth=max_depth)\n",
        "\n",
        "        # Merge the child graphs into the main graph\n",
        "        graph = nx.compose(graph, child_graph)\n",
        "\n",
        "    return graph\n",
        "\n",
        "# Main program flow\n",
        "if __name__ == \"__main__\":\n",
        "    # Specify your seed concepts\n",
        "    concept1 = \"Cat\"\n",
        "    concept2 = \"Dog\"\n",
        "\n",
        "    # Set the maximum depth for the recursive exploration\n",
        "    max_depth = 3\n",
        "\n",
        "    concept_graph = build_concept_graph(concept1, concept2, max_depth=max_depth)\n",
        "\n",
        "    # Analyze or visualize the concept graph (using NetworkX or other libraries)\n",
        "    # output graph to text file via write()\n",
        "    nx.write_dot(concept_graph, \"concept_graph.dot\")\n",
        "    # now output as plain text using file open() and write()\n",
        "    with open(\"concept_graph.txt\", \"w\") as f:\n",
        "        f.write(nx.nx_pydot.to_pydot(concept_graph).to_string())\n"
      ],
      "metadata": {
        "id": "lz7dVpXjA2uf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}